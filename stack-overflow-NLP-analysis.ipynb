{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow NLP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Overflow is a collaboratively edited question-and-answer site originally focused on programming topics. Because of the variety of features tracked, including a variety of feedback metrics, it allows for some open-ended analysis of user behavior on the site.\n",
    "\n",
    "Stack Exchange (the parent organization) provides an anonymized [data dump](https://archive.org/details/stackexchange), and we'll use Spark to perform data manipulation, analysis, and machine learning on this data set. As a side note, there's also an online data explorer which allows you to query the data interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats directory contains the data and there are three sub-folders, `allUsers`, `allPosts`, and `allVotes`, which contain Gzipped XML with the following format:\n",
    "\n",
    "```\n",
    "<row Body=\"&lt;p&gt;I always validate my web pages, and I recommend you do the same BUT many large company websites DO NOT and cannot validate because the importance of the website looking exactly the same on all systems requires rules to be broken. &lt;/p&gt;&#10;&#10;&lt;p&gt;In general, valid websites help your page look good even on odd configurations (like cell phones) so you should always at least try to make it validate.&lt;/p&gt;&#10;\" CommentCount=\"0\" CreationDate=\"2008-10-12T20:26:29.397\" Id=\"195995\" LastActivityDate=\"2008-10-12T20:26:29.397\" OwnerDisplayName=\"Eric Wendelin\" OwnerUserId=\"25066\" ParentId=\"195973\" PostTypeId=\"2\" Score=\"0\" />\n",
    "```\n",
    "\n",
    "The full schema is available as a text file as `stack_exchange_schema.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input and parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows are split across multiple lines; these can be discarded. Incorrectly formatted XML can also be ignored. It is enough to simply skip problematic rows, the loss of data will not significantly impact our results on this large data sets.\n",
    "\n",
    "We will need to handle XML parsing using `lxml.etree` in Python. We are going to take several shortcuts to speed up and simplify our computations.  First, our parsing function only attempts to parse rows that start with `  <row` as these denote actual data entries. This should be done in Spark as the data is being read in from disk, without any pre-Spark processing. We are going to use this cleaned dataset for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import os, time\n",
    "\n",
    "def localpath(path):\n",
    "    return 'file://' + os.path.join(os.path.abspath(os.path.curdir), path)\n",
    "\n",
    "sc = SparkContext(\"local[*]\", \"temp\")\n",
    "\n",
    "corpus = sc.textFile(localpath('stats-data/allPosts/'))\n",
    "corpus_user = sc.textFile(localpath('stats-data/allUsers/*'))\n",
    "corpus_votes = sc.textFile(localpath('stats-data/allVotes/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "\n",
    "def xml_parser(row):\n",
    "    if row[:6] == '  <row':\n",
    "        try:\n",
    "            tree = ET.fromstring(row)\n",
    "            return 0\n",
    "        except:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rows(row):\n",
    "    if '<row' in row:\n",
    "        try:\n",
    "            tree = ET.fromstring(row)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "corpus = corpus.filter(lambda x : clean_rows(x))\n",
    "corpus_user = corpus_user.filter(lambda x : clean_rows(x))\n",
    "corpus_votes = corpus_votes.filter(lambda x : clean_rows(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Favorites and scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in looking for useful patterns in the data. We're going to start by looking to see if there is a relationship between the number of times a post was favorited (the `FavoriteCount`) and the `Score`.  The score is the number of times the post was upvoted minus the number of times it was downvoted, so it is a measure of how much a post was liked.  We'd expect posts with a higher number of favorites to have better scores, since they're both measurements of how good the post is.\n",
    "\n",
    "Let's aggregate posts by the number of favorites, and find the average score for the lowest 50 number of favorites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZeroNone(x):\n",
    "    if x: return int(x)\n",
    "    else: return 0\n",
    "    \n",
    "\n",
    "def AggregateScore(x):\n",
    "    score = ZeroNone(ET.fromstring(x).get('Score'))\n",
    "    favorite = ZeroNone(ET.fromstring(x).get('FavoriteCount'))\n",
    "    return (favorite, (score, 1))\n",
    "\n",
    "\n",
    "favorite_score = corpus.map(lambda x : AggregateScore(x))\\\n",
    "                          .reduceByKey(lambda x,y : (x[0]+y[0], x[1]+y[1]))\\\n",
    "                           .map(lambda x: (x[0], x[1][0]/x[1][1]))\\\n",
    "                            .sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2.3398827696988396),\n",
       " (1, 2.7334613999279624),\n",
       " (2, 4.481914893617021),\n",
       " (3, 6.350249584026622),\n",
       " (4, 7.656934306569343),\n",
       " (5, 8.941888619854721),\n",
       " (6, 11.263779527559056),\n",
       " (7, 12.916666666666666),\n",
       " (8, 13.345864661654135),\n",
       " (9, 15.754237288135593),\n",
       " (10, 17.0),\n",
       " (11, 17.52542372881356),\n",
       " (12, 18.793650793650794),\n",
       " (13, 20.083333333333332),\n",
       " (14, 23.58823529411765),\n",
       " (15, 22.594594594594593),\n",
       " (16, 25.48148148148148),\n",
       " (17, 26.333333333333332),\n",
       " (18, 25.814814814814813),\n",
       " (19, 25.944444444444443),\n",
       " (20, 29.636363636363637),\n",
       " (21, 35.333333333333336),\n",
       " (22, 32.46153846153846),\n",
       " (23, 31.76923076923077),\n",
       " (24, 29.142857142857142),\n",
       " (25, 38.55555555555556),\n",
       " (26, 38.25),\n",
       " (27, 39.55555555555556),\n",
       " (28, 34.166666666666664),\n",
       " (29, 45.75),\n",
       " (30, 43.4),\n",
       " (31, 40.875),\n",
       " (32, 33.0),\n",
       " (33, 36.833333333333336),\n",
       " (34, 41.0),\n",
       " (35, 41.0),\n",
       " (36, 53.25),\n",
       " (37, 54.5),\n",
       " (38, 63.6),\n",
       " (39, 40.0),\n",
       " (40, 39.666666666666664),\n",
       " (41, 51.0),\n",
       " (42, 52.0),\n",
       " (44, 76.0),\n",
       " (45, 64.0),\n",
       " (47, 90.5),\n",
       " (48, 51.5),\n",
       " (49, 49.333333333333336),\n",
       " (50, 53.0),\n",
       " (52, 57.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite_score.collect()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate the correlation between a user's reputation and the type of their posts. For 100 users with the highest reputation, let's single out posts which are either questions or answers and look at the percentage of these posts that are answers: *(answers / (answers + questions))*.\n",
    "\n",
    "This can be done with either rdds or dataframes. Since we used rdd in the previous task, let's try dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "def q_count(row):\n",
    "    #this function counts the questions\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('PostTypeId') == '1' and tree.attrib.get('OwnerUserId'):\n",
    "        return (int(tree.attrib.get('OwnerUserId')), 1)\n",
    "    else:\n",
    "        return -1000\n",
    "    \n",
    "def a_count(row):\n",
    "    #this function counts the answers\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('PostTypeId') == '2' and tree.attrib.get('OwnerUserId'):\n",
    "        return (int(tree.attrib.get('OwnerUserId')), 1)\n",
    "    else:\n",
    "        return -1000 \n",
    "\n",
    "def user_rep(row):\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('Reputation') and tree.attrib.get('Id'):\n",
    "        return (int(tree.attrib.get('Id')), int(tree.attrib.get('Reputation')))\n",
    "    else:\n",
    "        return -1000\n",
    "\n",
    "#We have 3 tables, first one is the count of questions, second one \n",
    "#is the count of answers and the last one has reputations per id\n",
    "reps_per_user = corpus_user.map(lambda x: user_rep(x)).filter(lambda x: x != -1000)\\\n",
    "                            .toDF(['rep_id','reputation'])#.sort(col(\"reputation\").desc()).limit(100)\n",
    "\n",
    "q_count_id = corpus.map(lambda x: q_count(x)).filter(lambda x: x != -1000).reduceByKey(lambda x, y: x + y)\\\n",
    "                    .reduceByKey(lambda x, y: x + y).toDF(['q_id','question_count'])\n",
    "\n",
    "a_count_id = corpus.map(lambda x: a_count(x)).filter(lambda x: x != -1000)\\\n",
    "                    .reduceByKey(lambda x, y: x + y).toDF(['a_id','answer_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's join these tables\n",
    "first_join = q_count_id.join(a_count_id, q_count_id.q_id == a_count_id.a_id,'full')\n",
    "first_join = first_join.drop('a_id')\n",
    "full_join = first_join.join(reps_per_user, first_join.q_id == reps_per_user.rep_id,'full')\n",
    "full_join = full_join.drop('q_id')\n",
    "full_join = full_join.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------+----------+--------------------+\n",
      "|question_count|answer_count|rep_id|reputation|                frac|\n",
      "+--------------+------------+------+----------+--------------------+\n",
      "|             4|        1206|   919|    100976|   0.996694214876033|\n",
      "|             9|        2227|   805|     92624|  0.9959749552772809|\n",
      "|            31|        1543|   686|     47334|  0.9803049555273189|\n",
      "|             7|         856|  7290|     46907|  0.9918887601390498|\n",
      "|             8|         430|   930|     32283|  0.9817351598173516|\n",
      "|             0|           0|  4505|     27599|                null|\n",
      "|             5|         549|  4253|     25406|  0.9909747292418772|\n",
      "|            75|         418|   183|     23610|   0.847870182555781|\n",
      "|            12|         953| 11032|     23102|  0.9875647668393782|\n",
      "|            18|         552| 28746|     22706|   0.968421052631579|\n",
      "|             8|         382|   887|     20315|  0.9794871794871794|\n",
      "|             8|         287|   159|     20133|  0.9728813559322034|\n",
      "|             6|         354|  2116|     19312|  0.9833333333333333|\n",
      "|             9|         188|  4856|     18866|  0.9543147208121827|\n",
      "|             0|           0| 22047|     17719|                null|\n",
      "|             5|         388|  5739|     16854|  0.9872773536895675|\n",
      "|            13|         283|  3277|     16131|   0.956081081081081|\n",
      "|            11|         313|    88|     14768|  0.9660493827160493|\n",
      "|             0|           0|  2970|     14500|                null|\n",
      "|             9|         386|   601|     14100|  0.9772151898734177|\n",
      "|             1|         333| 17230|     13557|  0.9970059880239521|\n",
      "|             0|           0|   449|     13078|                null|\n",
      "|             8|         282|  2392|     12491|  0.9724137931034482|\n",
      "|            11|         176|  1390|     12098|  0.9411764705882353|\n",
      "|            41|         226|  5836|     11989|   0.846441947565543|\n",
      "|             0|           0|  7555|     11865|                null|\n",
      "|            51|         226|   603|     11830|  0.8158844765342961|\n",
      "|             6|         333|  7972|     11795|  0.9823008849557522|\n",
      "|             2|         226|  6633|     11662|  0.9912280701754386|\n",
      "|             2|         285|  2958|     11083|  0.9930313588850174|\n",
      "|             7|         227|  9394|     10750|  0.9700854700854701|\n",
      "|             7|         461|  7828|     10728|  0.9850427350427351|\n",
      "|            52|         238|  2817|     10552|  0.8206896551724138|\n",
      "|             4|         161|  7224|     10394|  0.9757575757575757|\n",
      "|             4|         276|  4598|     10383|  0.9857142857142858|\n",
      "|            30|         306|  7071|     10045|  0.9107142857142857|\n",
      "|             1|         194|  1739|      9619|  0.9948717948717949|\n",
      "|             9|         189|  1036|      9530|  0.9545454545454546|\n",
      "|             0|           0|  3382|      9294|                null|\n",
      "|            33|         311|  8013|      9047|  0.9040697674418605|\n",
      "|            19|         114|  3019|      8794|  0.8571428571428571|\n",
      "|             4|         105|  4376|      8629|   0.963302752293578|\n",
      "|             1|         131|   251|      8221|  0.9924242424242424|\n",
      "|            18|         162| 28666|      8013|                 0.9|\n",
      "|            18|         249|  1764|      7971|  0.9325842696629213|\n",
      "|             0|           0| 23853|      7765|                null|\n",
      "|             1|         248| 32036|      7729|  0.9959839357429718|\n",
      "|             8|         158| 10849|      7725|  0.9518072289156626|\n",
      "|             5|         157| 26338|      7608|  0.9691358024691358|\n",
      "|             2|         204|  1352|      7552|  0.9902912621359223|\n",
      "|            14|         145|   401|      7116|  0.9119496855345912|\n",
      "|            17|         100|     5|      6962|  0.8547008547008547|\n",
      "|            12|         107|     8|      6948|  0.8991596638655462|\n",
      "|             2|         161|  7250|      6888|  0.9877300613496932|\n",
      "|             4|          79|  1909|      6814|  0.9518072289156626|\n",
      "|             7|         100| 21054|      6716|  0.9345794392523364|\n",
      "|             4|         161|  4257|      6694|  0.9757575757575757|\n",
      "|            51|         142|   196|      6682|  0.7357512953367875|\n",
      "|            17|         115|   442|      6588|  0.8712121212121212|\n",
      "|             0|           0|   279|      6367|                null|\n",
      "|            16|         285|  2669|      6352|   0.946843853820598|\n",
      "|            72|         135|  8402|      6208|  0.6521739130434783|\n",
      "|             4|         359| 36041|      6149|  0.9889807162534435|\n",
      "|             0|           0|  2126|      6145|                null|\n",
      "|            23|         215| 44269|      6127|  0.9033613445378151|\n",
      "|             0|           0|  6029|      6040|                null|\n",
      "|             4|         110| 11981|      5970|  0.9649122807017544|\n",
      "|             3|          91|  1934|      5967|  0.9680851063829787|\n",
      "|            69|         144|   795|      5849|   0.676056338028169|\n",
      "|             3|         223| 25433|      5775|  0.9867256637168141|\n",
      "|           116|          68|   253|      5762|  0.3695652173913043|\n",
      "|            47|          97|   364|      5739|  0.6736111111111112|\n",
      "|            13|         143|    25|      5661|  0.9166666666666666|\n",
      "|             7|         110| 22311|      5500|  0.9401709401709402|\n",
      "|             0|           0|   334|      5444|                null|\n",
      "|             4|         146| 13047|      5398|  0.9733333333333334|\n",
      "|             4|          66|  8507|      5315|  0.9428571428571428|\n",
      "|            12|         116|   264|      5085|             0.90625|\n",
      "|            18|         159| 14188|      5042|  0.8983050847457628|\n",
      "|             0|           0|   307|      4934|                null|\n",
      "|             6|          84|  8076|      4795|  0.9333333333333333|\n",
      "|             0|           0|  5862|      4656|                null|\n",
      "|             1|          60|  8413|      4438|  0.9836065573770492|\n",
      "|            14|          70|  1307|      4238|  0.8333333333333334|\n",
      "|            17|         138|  2860|      4204|  0.8903225806451613|\n",
      "|            12|          73|   223|      4192|  0.8588235294117647|\n",
      "|             4|         169| 11887|      4149|   0.976878612716763|\n",
      "|             5|         139| 52554|      4147|  0.9652777777777778|\n",
      "|             0|           0|  2074|      4127|                null|\n",
      "|             8|         148| 35989|      4092|  0.9487179487179487|\n",
      "|           289|           1|  1005|      4080|0.003448275862068...|\n",
      "|            11|          63| 22228|      4065|  0.8513513513513513|\n",
      "|             8|          70|  4862|      3971|  0.8974358974358975|\n",
      "|             1|          67|  3601|      3958|  0.9852941176470589|\n",
      "|             0|           0| 17908|      3957|                null|\n",
      "|            20|         127| 13138|      3821|  0.8639455782312925|\n",
      "|             1|          35|  1108|      3805|  0.9722222222222222|\n",
      "|             6|          97|  1679|      3747|   0.941747572815534|\n",
      "|             0|           0| 11852|      3732|                null|\n",
      "|             1|          23|  8373|      3720|  0.9583333333333334|\n",
      "+--------------+------------+------+----------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's calculate the fraction of (answers / (answers + questions))\n",
    "full_join = full_join.sort(col(\"reputation\").desc())\n",
    "percentage_df = full_join.withColumn('frac', full_join.answer_count / (full_join.answer_count + full_join.question_count))\n",
    "percentage_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd expect the first **question** a user asks to be indicative of their future behavior.  We'll dig more into that further in the notebook, but for now let's see the relationship between reputation and how long it took each person to ask their first question.\n",
    "\n",
    "For each user that asked a question, let's find the difference between when their account was created (`CreationDate` for the User) and when they asked their first question (`CreationDate` for their first question).  We will return this time difference in days (round down, so 2.7 days counts as 2 days) for the 100 users with the highest reputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def user_dates(row):\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('OwnerUserId') and tree.attrib.get('CreationDate') and tree.attrib.get('PostTypeId') == '2':\n",
    "        return (tree.attrib.get('OwnerUserId'), \n",
    "                datetime.strptime(tree.attrib.get('CreationDate')[:-4], '%Y-%m-%dT%H:%M:%S'))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "min_date_per_user = corpus.map(lambda x: user_dates(x)).filter(lambda x: x != 0)\\\n",
    "                        .reduceByKey(lambda x, y: min(x,y)).toDF(['id','first_q_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_q_date = min_date_per_user.join(percentage_df, min_date_per_user.id == percentage_df.rep_id,'left')\n",
    "columns_to_drop = ['id', 'frac']\n",
    "first_q_date = first_q_date.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_creation(row):\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('Id') and tree.attrib.get('CreationDate'):\n",
    "        return (tree.attrib.get('Id'), \n",
    "                datetime.strptime(tree.attrib.get('CreationDate')[:-4], '%Y-%m-%dT%H:%M:%S'))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "creation_date_per_user = corpus_user.map(lambda x: user_creation(x)).filter(lambda x: x != 0)\\\n",
    "                                    .toDF(['id','creation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have two tables together with the initial table we constructed in the previous section.\n",
    "#First one is the ids and the creation dates table and the second one is the first question date table.\n",
    "soln_table = first_q_date.join(creation_date_per_user, first_q_date.rep_id == creation_date_per_user.id, 'left')\n",
    "soln_table = soln_table.drop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+------------+------+----------+-------------------+--------------------+\n",
      "|       first_q_date|question_count|answer_count|rep_id|reputation|      creation_date|         first_q_dif|\n",
      "+-------------------+--------------+------------+------+----------+-------------------+--------------------+\n",
      "|2010-08-13 15:48:29|             4|        1206|   919|    100976|2010-08-13 15:29:47|0.012986111111111111|\n",
      "|2010-08-09 00:37:45|             9|        2227|   805|     92624|2010-08-07 08:40:07|  1.6650231481481481|\n",
      "|2010-08-03 19:51:33|            31|        1543|   686|     47334|2010-08-03 19:42:40|0.006168981481481482|\n",
      "|2011-11-10 04:08:06|             7|         856|  7290|     46907|2011-11-09 04:43:15|  0.9755902777777777|\n",
      "|2010-08-19 08:50:44|             8|         430|   930|     32283|2010-08-13 20:50:47|   5.499965277777778|\n",
      "|2011-05-08 02:49:16|             0|           0|  4505|     27599|2011-05-07 13:44:25|  0.5450347222222223|\n",
      "|2011-04-20 12:59:07|             5|         549|  4253|     25406|2011-04-20 12:59:07|                 0.0|\n",
      "|2010-07-20 03:11:36|            75|         418|   183|     23610|2010-07-20 02:56:34|0.010439814814814815|\n",
      "|2012-05-02 15:41:40|            12|         953| 11032|     23102|2012-05-02 14:04:04| 0.06777777777777778|\n",
      "|2013-08-03 01:22:46|            18|         552| 28746|     22706|2013-08-02 14:24:21|  0.4572337962962963|\n",
      "|2010-08-12 07:45:05|             8|         382|   887|     20315|2010-08-12 07:45:05|                 0.0|\n",
      "|2010-07-19 23:26:31|             8|         287|   159|     20133|2010-07-19 23:05:39|0.014490740740740742|\n",
      "|2010-12-08 12:15:49|             6|         354|  2116|     19312|2010-11-24 09:52:34|  14.099479166666667|\n",
      "|2011-06-02 17:51:30|             9|         188|  4856|     18866|2011-06-02 17:45:51|0.003923611111111111|\n",
      "|2013-03-18 20:20:43|             0|           0| 22047|     17719|2013-03-15 13:57:54|  3.2658449074074074|\n",
      "|2011-08-08 21:29:26|             5|         388|  5739|     16854|2011-08-08 17:31:44| 0.16506944444444444|\n",
      "|2011-03-14 12:52:57|            13|         283|  3277|     16131|2011-02-16 19:33:34|  25.680127314814815|\n",
      "|2010-07-10 20:00:16|            11|         313|    88|     14768|2010-07-19 19:35:37|  -8.982881944444445|\n",
      "|2011-01-29 22:03:58|             0|           0|  2970|     14500|2011-01-29 21:42:27| 0.01494212962962963|\n",
      "|2010-07-29 14:29:16|             9|         386|   601|     14100|2010-07-29 14:29:12|4.629629629629629...|\n",
      "+-------------------+--------------+------------+------+----------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp\n",
    "#Let's add a column that is the time between the creation time and the first question time\n",
    "soln_table = soln_table.withColumn('first_q_dif', (unix_timestamp('first_q_date') - unix_timestamp('creation_date'))/86400)\n",
    "soln_table = soln_table.sort(col(\"reputation\").desc())\n",
    "soln_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify veterans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be interesting to think about what factors influence a user to remain active on the site over a long period of time. In order not to bias the results towards older users, we'll define a time window between 100 and 150 days after account creation. If the user has made a post in this time, we'll consider them active and well on their way to being veterans of the site; if not, they are inactive and were likely brief users.\n",
    "\n",
    "For each group separately, we can average the score, views, number of answers, and number of favorites of the users' **first question**. Let's see if there are differences between the first ever question posts of \"veterans\" vs. \"brief users\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_creation(row):\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('Id') and tree.attrib.get('CreationDate'):\n",
    "        return (tree.attrib.get('Id'), \n",
    "                datetime.strptime(tree.attrib.get('CreationDate')[:-4], '%Y-%m-%dT%H:%M:%S'))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "creation_date_dict = {key: value for key, value in corpus_user.map(lambda x : user_creation(x)).collect()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vet_brief(row):\n",
    "    #this function identifies whether the user is a veteran or a brief user\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('OwnerUserId') in creation_date_dict.keys():\n",
    "        if (datetime.strptime(tree.attrib.get('CreationDate')[:-4], '%Y-%m-%dT%H:%M:%S') - \\\n",
    "        creation_date_dict[tree.attrib.get('OwnerUserId')]).total_seconds() / 86400 >= 100  \\\n",
    "        and (datetime.strptime(tree.attrib.get('CreationDate')[:-4], '%Y-%m-%dT%H:%M:%S') - \\\n",
    "        creation_date_dict[tree.attrib.get('OwnerUserId')]).total_seconds() / 86400 <= 150 :\n",
    "            \n",
    "            return (tree.attrib.get('OwnerUserId'), 1)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return (tree.attrib.get('OwnerUserId'), 0)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vet_brief_dict = {key: value for key, value in corpus.map(lambda x: vet_brief(x)).filter(lambda x: x != 0)\n",
    "                  .reduceByKey(lambda x, y: max(x,y)).collect()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_variables(row):\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('OwnerUserId') in vet_brief_dict.keys() and tree.attrib.get('PostTypeId') == '1':\n",
    "        return (tree.attrib.get('OwnerUserId'), \n",
    "                (datetime.strptime(tree.attrib.get('CreationDate')[:-4], '%Y-%m-%dT%H:%M:%S'),\n",
    "                int(tree.attrib.get('Score') or 0), int(tree.attrib.get('ViewCount') or 0), \n",
    "                int(tree.attrib.get('FavoriteCount') or 0),int(tree.attrib.get('AnswerCount') or 0),1))\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def variable_count(tple):\n",
    "    if vet_brief_dict[tple[0]] == 1:\n",
    "        return ('veteran',tple[1][1:])\n",
    "    else:\n",
    "        return ('brief',tple[1][1:])\n",
    "\n",
    " \n",
    "all_variables_dict = corpus.map(lambda x: all_variables(x)).filter(lambda x: x != 0)\\\n",
    "                        .reduceByKey(lambda x,y: x if(x[0] < y[0]) else y).map(lambda x: variable_count(x))\\\n",
    "                        .reduceByKey(lambda x,y: ((x[0]+y[0]),x[1]+y[1],x[2]+y[2],x[3]+y[3],x[4]+y[4])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vet_score': 3.5434543454345433,\n",
       " 'vet_views': 926.3982398239824,\n",
       " 'vet_answers': 1.2981298129812981,\n",
       " 'vet_favorites': 1.300880088008801,\n",
       " 'brief_score': 2.1008600836584104,\n",
       " 'brief_views': 553.5200921182497,\n",
       " 'brief_answers': 0.9707195563284298,\n",
       " 'brief_favorites': 0.5758800582788927}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identify_veterans = {}\n",
    "for el in all_variables_dict:\n",
    "    if el[0] == 'veteran':\n",
    "        identify_veterans['vet_score'] = float(el[1][0])/el[1][4]\n",
    "        identify_veterans['vet_views'] = float(el[1][1])/el[1][4]\n",
    "        identify_veterans['vet_answers'] = float(el[1][3])/el[1][4]\n",
    "        identify_veterans['vet_favorites'] = float(el[1][2])/el[1][4]\n",
    "    else:\n",
    "        identify_veterans['brief_score'] = float(el[1][0])/el[1][4]\n",
    "        identify_veterans['brief_views'] = float(el[1][1])/el[1][4]\n",
    "        identify_veterans['brief_answers'] = float(el[1][3])/el[1][4]\n",
    "        identify_veterans['brief_favorites'] = float(el[1][2])/el[1][4]\n",
    "\n",
    "identify_veterans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is an alternative approach for vectorizing text data. The vectorized representations of words in the vocabulary tend to be useful for predicting other words in the document, hence the famous example \"vector('king') - vector('man') + vector('woman') ~= vector('queen')\".\n",
    "\n",
    "Let's see how good a Word2Vec model we can train using the tags of each Stack Exchange post as documents (this uses the full data set). We can use the implementation of Word2Vec from Spark ML (this will require using DataFrames) to return a list of the top 25 closest synonyms to \"ggplot2\" and their similarity score in tuple format (\"string\", number).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(row):    \n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('Tags'):\n",
    "        tag = tree.attrib.get('Tags')\n",
    "        return tag\n",
    "\n",
    "corpus_tags = corpus.map(lambda x : get_tags(x)).filter(lambda x: x != None)\\\n",
    "                    .map(lambda x: (x.replace('>', ' ').replace('<', ' ').split(), 1)).toDF(['text', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(inputCol=\"text\", outputCol=\"vectors\", vectorSize=100, minCount=10, seed=42)\n",
    "model = w2v.fit(corpus_tags)\n",
    "result = model.transform(corpus_tags)\n",
    "vectors = model.getVectors().rdd.map(lambda x: (x.word, x.vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dataframe', 0.838861882686615),\n",
       " ('data-visualization', 0.8181682825088501),\n",
       " ('latent-class', 0.8178013563156128),\n",
       " ('nls', 0.7952163815498352),\n",
       " ('traminer', 0.7847820520401001),\n",
       " ('package', 0.772851288318634),\n",
       " ('gam', 0.7597593069076538),\n",
       " ('plm', 0.7597370743751526),\n",
       " ('mlogit', 0.756221354007721),\n",
       " ('survival', 0.7530490159988403),\n",
       " ('glmnet', 0.7521149516105652),\n",
       " ('lm', 0.7484762668609619),\n",
       " ('marginal-effect', 0.7238023281097412),\n",
       " ('quantile-regression', 0.7158777117729187),\n",
       " ('dlm', 0.7119066119194031),\n",
       " ('loess', 0.7080047130584717),\n",
       " ('constrained-regression', 0.6954183578491211),\n",
       " ('vecm', 0.6798256039619446),\n",
       " ('scatterplot', 0.6721137762069702),\n",
       " ('propensity-scores', 0.636638879776001),\n",
       " ('stepwise-regression', 0.6130045056343079),\n",
       " ('growth-mixture-model', 0.6100594401359558),\n",
       " ('interpolation', 0.6031655073165894),\n",
       " ('correlated-predictors', 0.5945377945899963),\n",
       " ('latex', 0.590451717376709)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_rdd = model.findSynonyms('ggplot2', 25).rdd.take(25)\n",
    "\n",
    "word2vec = []\n",
    "for i,el in enumerate(word2vec_rdd):\n",
    "    word2vec.append((el.word,el.similarity))\n",
    "\n",
    "word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to see if we can predict the tags of a question from its body text. Instead of predicting specific tags, we will instead try to predict if a question contains one of the top ten most common tags. To do this, the dataset is separated out as a train and a test set.\n",
    "\n",
    "This will involve two steps: first, find the ten most common tags for questions in the training data set (the tags have been removed from the test set). Then train a model to predict from the text of the question (the `Body` attribute) if it has one of those ten tags in it - we need to process the question text with NLP techniques such as splitting the text into tokens.\n",
    "\n",
    "Since we can't reliably pickle Spark models, instead we will return a list of the predictions, sorted by the question's `Id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "def localpath(path):\n",
    "    return 'file://' + os.path.join(os.path.abspath(os.path.curdir), path)\n",
    "\n",
    "\n",
    "sc = SparkContext(\"local[*]\", \"temp\")\n",
    "\n",
    "classification_train = sc.textFile(localpath('stats-data/train/'))\n",
    "classification_test = sc.textFile(localpath('stats-data/test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rows(row):\n",
    "    if '<row' in row:\n",
    "        try:\n",
    "            tree = ET.fromstring(row)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "rows = classification_train.filter(lambda x : clean_rows(x))\n",
    "rows_test = classification_test.filter(lambda x : clean_rows(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(row):    \n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('Tags'):\n",
    "        tag = tree.attrib.get('Tags')\n",
    "        return tag\n",
    "    \n",
    "tags = rows.map(lambda x : get_tags(x)).filter(lambda x: x != None)\\\n",
    "            .flatMap(lambda x: x.replace('>', ' ').replace('<', ' ').split()).map(lambda x: (x,1))\\\n",
    "            .reduceByKey(lambda x, y: x + y).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r',\n",
       " 'regression',\n",
       " 'time-series',\n",
       " 'machine-learning',\n",
       " 'probability',\n",
       " 'hypothesis-testing',\n",
       " 'distributions',\n",
       " 'self-study',\n",
       " 'logistic',\n",
       " 'correlation']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_sorted = sorted(tags, key=lambda x: x[1], reverse=True)[:10]\n",
    "top_ten_tags = [x[0] for x in tags_sorted]\n",
    "top_ten_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_body_label(row):\n",
    "    tree = ET.fromstring(row)\n",
    "    if tree.attrib.get('Body') and tree.attrib.get('Tags'):\n",
    "        row_tags = tree.attrib.get('Tags').replace('>', ' ').replace('<', ' ').split()\n",
    "        for el in row_tags:\n",
    "            if el in top_ten_tags:\n",
    "                return (int(tree.attrib.get('Id')), tree.attrib.get('Body'), 1)\n",
    "\n",
    "        return (int(tree.attrib.get('Id')), tree.attrib.get('Body'), 0)\n",
    "\n",
    "id_body_label = rows.map(lambda x : get_id_body_label(x)).filter(lambda x: x != None).collect()\n",
    "id_body_label_test = rows_test.map(lambda x : get_id_body_label(x)).filter(lambda x: x != None).collect()\n",
    "\n",
    "body = [x[1] for x in id_body_label]\n",
    "labels = [x[2] for x in id_body_label]\n",
    "body_test = [x[1] for x in id_body_label_test]\n",
    "labels_test = [x[2] for x in id_body_label_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "normalized_est = Pipeline([\n",
    "    ('tfidfvec', TfidfVectorizer()),\n",
    "    ('regressor',RidgeClassifier())\n",
    "])\n",
    "normalized_est.fit(body, labels)\n",
    "normalized_est.predict(body_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
